<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Regression on STOR-i Blog</title>
    <link>https://mikeoma.github.io/tags/regression/</link>
    <description>Recent content in Regression on STOR-i Blog</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Mon, 23 Apr 2018 00:00:00 +0000</lastBuildDate>
    
	<atom:link href="https://mikeoma.github.io/tags/regression/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Model Selection</title>
      <link>https://mikeoma.github.io/blog/2018-04-23-model-selection/</link>
      <pubDate>Mon, 23 Apr 2018 00:00:00 +0000</pubDate>
      
      <guid>https://mikeoma.github.io/blog/2018-04-23-model-selection/</guid>
      <description>I’ve done a couple blogposts in the past on Statistical learning, see here if you havn’t read them yet. In this blog post I’ll explain the most popular way to compare models and decide which one is best. It’s known as the test-train split. This is really only useful for supervised problems.
The test set approach So the test-set approach is quite intuitive when you hear about it. You have your \(n\) data-points you observed each of which has explanatory \(x_i\) and response \(y_i\) and our end goal is to predict the \(y_i\).</description>
    </item>
    
    <item>
      <title>Supervised or not?</title>
      <link>https://mikeoma.github.io/blog/2018-03-20-supervised-or-not/</link>
      <pubDate>Tue, 20 Mar 2018 00:00:00 +0000</pubDate>
      
      <guid>https://mikeoma.github.io/blog/2018-03-20-supervised-or-not/</guid>
      <description>MACHINE LEARNING!!! So, if you’ve not heard of machine learning yet, you probably haven’t been watching any TV the last decade. Problem is machine learning is absolutely massive field.
This is the intro to a series of blog posts I plan on doing on various areas in machine learning, more specifically statistically backed methods therefore I call it statistical learning. In this blog post I aim to break down the two main areas that are generally focused on.</description>
    </item>
    
  </channel>
</rss>