<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Regression on STOR-i Blog</title>
    <link>/tags/regression/</link>
    <description>Recent content in Regression on STOR-i Blog</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Thu, 19 Apr 2018 00:00:00 +0000</lastBuildDate>
    
	<atom:link href="/tags/regression/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Validating Models</title>
      <link>/blog/2018-04-19-validating-models/</link>
      <pubDate>Thu, 19 Apr 2018 00:00:00 +0000</pubDate>
      
      <guid>/blog/2018-04-19-validating-models/</guid>
      <description>Previously I made a blog post on supervised or unsupervised learning, here I’ll continue on and add a bit more detail about how you can check how well your model fits your data. I’ll talk about the two main approachs: using the statistical liklihood approach and the test set approach.</description>
    </item>
    
    <item>
      <title>Supervised or not?</title>
      <link>/blog/2018-03-20-supervised-or-not/</link>
      <pubDate>Tue, 20 Mar 2018 00:00:00 +0000</pubDate>
      
      <guid>/blog/2018-03-20-supervised-or-not/</guid>
      <description>MACHINE LEARNING!!! So, if you’ve not heard of machine learning yet, you probably haven’t been watching any TV the last decade. Problem is machine learning is absolutely massive field.
This is the intro to a series of blog posts I plan on doing on various areas in machine learning, more specifically statistically backed methods therefore I call it statistical learning. In this blog post I aim to break down the two main areas that are generally focused on.</description>
    </item>
    
  </channel>
</rss>